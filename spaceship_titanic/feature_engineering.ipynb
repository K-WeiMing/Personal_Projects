{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Sci-kit learn\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/spaceship_titanic/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the predicted label\n",
    "training_labels = df_train.pop('Transported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8693 entries, 0 to 8692\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   PassengerId   8693 non-null   object \n",
      " 1   HomePlanet    8492 non-null   object \n",
      " 2   CryoSleep     8476 non-null   object \n",
      " 3   Cabin         8494 non-null   object \n",
      " 4   Destination   8511 non-null   object \n",
      " 5   Age           8514 non-null   float64\n",
      " 6   VIP           8490 non-null   object \n",
      " 7   RoomService   8512 non-null   float64\n",
      " 8   FoodCourt     8510 non-null   float64\n",
      " 9   ShoppingMall  8485 non-null   float64\n",
      " 10  Spa           8510 non-null   float64\n",
      " 11  VRDeck        8505 non-null   float64\n",
      " 12  Name          8493 non-null   object \n",
      "dtypes: float64(6), object(7)\n",
      "memory usage: 883.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns_List = List[str]\n",
    "def drop_columns(df: pd.DataFrame, cols: Columns_List):\n",
    "    df.drop(cols, axis = 1, inplace = True)\n",
    "    return df\n",
    "\n",
    "df_train = drop_columns(df_train, [\"Name\", \"Cabin\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']\n",
      "Continuous columns: ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = df_train.select_dtypes(include=['object']).columns.to_list()\n",
    "cont_cols = df_train.select_dtypes(include=['float64']).columns.to_list()\n",
    "\n",
    "# Exclude passenger ID as categorical column\n",
    "cat_cols.pop(cat_cols.index('PassengerId'))\n",
    "\n",
    "print(f\"Categorical columns: {cat_cols}\")\n",
    "print(f\"Continuous columns: {cont_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_encoder = OrdinalEncoder()\n",
    "df_train[cat_cols] = ord_encoder.fit_transform(df_train[cat_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous variables\n",
    "\n",
    "iterative_imputer = IterativeImputer()\n",
    "\n",
    "df_train[cont_cols] = pd.DataFrame(iterative_imputer.fit_transform(df_train[cont_cols]), columns = cont_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df_train[cat_cols] = pd.DataFrame(categorical_imputer.fit_transform(df_train[cat_cols]), columns = cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check on any remaining missing values\n",
    "df_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get group number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group number is in passenger id (first half)\n",
    "df_train['group'] = df_train['PassengerId'].str.split('_').str[0]\n",
    "df_train['group'] = pd.to_numeric(df_train['group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    3\n",
       "4    4\n",
       "5    5\n",
       "6    6\n",
       "7    6\n",
       "8    7\n",
       "9    8\n",
       "Name: group, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "df_train['group'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove passengerId as its not needed anymore\n",
    "df_train.drop('PassengerId', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noramlize values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "normalized_cols = [col + '_norm' for col in cont_cols]\n",
    "df_train[normalized_cols] = std_scaler.fit_transform(df_train[cont_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_norm</th>\n",
       "      <th>RoomService_norm</th>\n",
       "      <th>FoodCourt_norm</th>\n",
       "      <th>ShoppingMall_norm</th>\n",
       "      <th>Spa_norm</th>\n",
       "      <th>VRDeck_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.709373</td>\n",
       "      <td>-0.340420</td>\n",
       "      <td>-0.286919</td>\n",
       "      <td>-0.290836</td>\n",
       "      <td>-0.276256</td>\n",
       "      <td>-0.268140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.336374</td>\n",
       "      <td>-0.175210</td>\n",
       "      <td>-0.281279</td>\n",
       "      <td>-0.248989</td>\n",
       "      <td>0.211620</td>\n",
       "      <td>-0.229322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.033985</td>\n",
       "      <td>-0.275245</td>\n",
       "      <td>1.954387</td>\n",
       "      <td>-0.290836</td>\n",
       "      <td>5.691115</td>\n",
       "      <td>-0.224911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.291074</td>\n",
       "      <td>-0.340420</td>\n",
       "      <td>0.517218</td>\n",
       "      <td>0.330181</td>\n",
       "      <td>2.682103</td>\n",
       "      <td>-0.097871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.894105</td>\n",
       "      <td>0.118835</td>\n",
       "      <td>-0.243046</td>\n",
       "      <td>-0.038077</td>\n",
       "      <td>0.225839</td>\n",
       "      <td>-0.266375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_norm  RoomService_norm  FoodCourt_norm  ShoppingMall_norm  Spa_norm  \\\n",
       "0  0.709373         -0.340420       -0.286919          -0.290836 -0.276256   \n",
       "1 -0.336374         -0.175210       -0.281279          -0.248989  0.211620   \n",
       "2  2.033985         -0.275245        1.954387          -0.290836  5.691115   \n",
       "3  0.291074         -0.340420        0.517218           0.330181  2.682103   \n",
       "4 -0.894105          0.118835       -0.243046          -0.038077  0.225839   \n",
       "\n",
       "   VRDeck_norm  \n",
       "0    -0.268140  \n",
       "1    -0.229322  \n",
       "2    -0.224911  \n",
       "3    -0.097871  \n",
       "4    -0.266375  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check on normalized columns\n",
    "df_train[normalized_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>group</th>\n",
       "      <th>Age_norm</th>\n",
       "      <th>RoomService_norm</th>\n",
       "      <th>FoodCourt_norm</th>\n",
       "      <th>ShoppingMall_norm</th>\n",
       "      <th>Spa_norm</th>\n",
       "      <th>VRDeck_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.709373</td>\n",
       "      <td>-0.340420</td>\n",
       "      <td>-0.286919</td>\n",
       "      <td>-0.290836</td>\n",
       "      <td>-0.276256</td>\n",
       "      <td>-0.268140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.336374</td>\n",
       "      <td>-0.175210</td>\n",
       "      <td>-0.281279</td>\n",
       "      <td>-0.248989</td>\n",
       "      <td>0.211620</td>\n",
       "      <td>-0.229322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.033985</td>\n",
       "      <td>-0.275245</td>\n",
       "      <td>1.954387</td>\n",
       "      <td>-0.290836</td>\n",
       "      <td>5.691115</td>\n",
       "      <td>-0.224911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.291074</td>\n",
       "      <td>-0.340420</td>\n",
       "      <td>0.517218</td>\n",
       "      <td>0.330181</td>\n",
       "      <td>2.682103</td>\n",
       "      <td>-0.097871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.894105</td>\n",
       "      <td>0.118835</td>\n",
       "      <td>-0.243046</td>\n",
       "      <td>-0.038077</td>\n",
       "      <td>0.225839</td>\n",
       "      <td>-0.266375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HomePlanet  CryoSleep  Destination   Age  VIP  RoomService  FoodCourt  \\\n",
       "0         1.0        0.0          2.0  39.0  0.0          0.0        0.0   \n",
       "1         0.0        0.0          2.0  24.0  0.0        109.0        9.0   \n",
       "2         1.0        0.0          2.0  58.0  1.0         43.0     3576.0   \n",
       "3         1.0        0.0          2.0  33.0  0.0          0.0     1283.0   \n",
       "4         0.0        0.0          2.0  16.0  0.0        303.0       70.0   \n",
       "\n",
       "   ShoppingMall     Spa  VRDeck  group  Age_norm  RoomService_norm  \\\n",
       "0           0.0     0.0     0.0      1  0.709373         -0.340420   \n",
       "1          25.0   549.0    44.0      2 -0.336374         -0.175210   \n",
       "2           0.0  6715.0    49.0      3  2.033985         -0.275245   \n",
       "3         371.0  3329.0   193.0      3  0.291074         -0.340420   \n",
       "4         151.0   565.0     2.0      4 -0.894105          0.118835   \n",
       "\n",
       "   FoodCourt_norm  ShoppingMall_norm  Spa_norm  VRDeck_norm  \n",
       "0       -0.286919          -0.290836 -0.276256    -0.268140  \n",
       "1       -0.281279          -0.248989  0.211620    -0.229322  \n",
       "2        1.954387          -0.290836  5.691115    -0.224911  \n",
       "3        0.517218           0.330181  2.682103    -0.097871  \n",
       "4       -0.243046          -0.038077  0.225839    -0.266375  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CryoSleep            0.109874\n",
       "RoomService          0.083392\n",
       "Spa_norm             0.078700\n",
       "RoomService_norm     0.075452\n",
       "Spa                  0.071019\n",
       "VRDeck_norm          0.065167\n",
       "VRDeck               0.058075\n",
       "ShoppingMall         0.054294\n",
       "ShoppingMall_norm    0.052571\n",
       "FoodCourt            0.048197\n",
       "FoodCourt_norm       0.037833\n",
       "HomePlanet           0.022380\n",
       "group                0.021697\n",
       "Age                  0.014347\n",
       "Age_norm             0.012029\n",
       "VIP                  0.004811\n",
       "Destination          0.000000\n",
       "Name: MI Scores, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_scores = mutual_info_classif(df_train, training_labels)\n",
    "mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=df_train.columns)\n",
    "mi_scores = mi_scores.sort_values(ascending=False)\n",
    "mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Destination and VIP\n",
    "df_train.drop(['Destination', 'VIP'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_train, training_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSTitanic(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_path:str):\n",
    "        \"\"\"Initialize a Dataset Class for SS Titanic\n",
    "\n",
    "        Args:\n",
    "            csv_path (str): path to the csv file\n",
    "        \"\"\"\n",
    "        # Init the dataset\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # Split the data into X and y\n",
    "        self.X = \"\"\n",
    "        self.y = \"\"\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert idx from tensor to list due to pandas bug (that arises when using pytorch's random_split)\n",
    "        if isinstance(idx, torch.Tensor):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        return [self.X.iloc[idx].values, self.y[idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, h = 15, d_out = 1):\n",
    "        super.__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(d_in, h)\n",
    "        self.fc2 = nn.Linear(h, d_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(csv_file, n_epochs = 100):\n",
    "    \"\"\"Train the model\n",
    "\n",
    "    Args:\n",
    "        csv_file (_type_): _description_\n",
    "        epochs (int, optional): _description_. Defaults to 100.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the dataset\n",
    "    dataset = SSTitanic(csv_file)\n",
    "    \n",
    "    # Split into train and val\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    trainset, valset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    # DataLoaders\n",
    "    trainloader = DataLoader(trainset, batch_size = 200, shuffle = True)\n",
    "    valloader = DataLoader(valset, batch_size = 200, shuffle = False)\n",
    "    \n",
    "    # Set device\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Set the model settings\n",
    "    D_in, H = 19, 15\n",
    "    net = Net(D_in, H).to(device)\n",
    "    \n",
    "    # Loss function\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(net.parameters(), weight_decay = 0.0001)\n",
    "    \n",
    "    # Train the network\n",
    "    loss_per_iter = list()\n",
    "    loss_per_batch = list()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        # Define params each epoch\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Perform the usual actions of zero-ing gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward, backward, step\n",
    "            outputs = net(inputs.float())\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward() # Backward\n",
    "            optimizer.step() # Step\n",
    "            \n",
    "            # Save loss to plot\n",
    "            running_loss += loss.item()\n",
    "            loss_per_iter.append(loss.item())\n",
    "        \n",
    "        loss_per_batch.append(running_loss / (i+1))\n",
    "        running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('personal_projects')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34ea9849d6d48753674ba6cf88f8e517abe39317b38078576229854f69470f45"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
